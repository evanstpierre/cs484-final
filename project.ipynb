{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Number 5\n",
    "\n",
    "##### Harry Denell (hdenell@uwaterloo.ca) and Evan St. Pierre (e3stpier@uwaterloo.ca)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "learner-arch .jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgICAgMCAgIDAwMDBAYEBAQEBAgGBgUGCQgKCgkICQkKDA8MCgsOCwkJDRENDg8QEBEQCgwSExIQEw8QEBD/2wBDAQMDAwQDBAgEBAgQCwkLEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBD/wAARCAD5AmwDASIAAhEBAxEB/8QAHQABAQACAwEBAQAAAAAAAAAAAAcGCAMFCQQCAf/EAEwQAAAFAwIBBQwIBAMHBAMAAAABAgMEBQYHERIIExghl9UUFiI3OEFWV1h3ltMVFzFRdpW1tgkjMrImUqUkJSgzNFmnYXJzk3GBkf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDbPBvDJw2lTbnsK4eHzGtQqtjXJMpCpUu04Dzr8J3ZNp6lOLaNbpphS4zS3FGZqdZd1MzIxS+adwsezTir4Np3yQq/+DOIuh1r+in5IobluyFH9n0pTTdmQkJIvO5FeqxrUfmitF5iFVASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kOadwsezTir4Np3yRVQASrmncLHs04q+Dad8kY/kHh/4Sse2PXr4qXDNipyPQ6e/ONkrOp+59SEGaWkEmOpRrWrahKUpUo1KIiSozIjuolWaP8U3JYOJEeE1cFYOt1Zs+lK6VSzRIcStJeEpC5S6e0oj2oNLxks1EomnQ7XAOOGcSYbtPH7dPiQXaZT0qmR4jDbDDcx5RvSSbbbM0pRyzruhEpXRpqpZ6qOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmnEPSqlJxfOua34TsuuWVIj3bS2GE6vSHoDhPritn5jksIfimf+WSr7xQKTVabXqVCrlGmtTIFRjty4shlW5DzLiSUhaT85GkyMj+4x9YlXDv8A7gtitYlc8FeNa5It2Kgv6U0s0olUtCfOom4EqIyavO4w4XmMBVQAAASrnY8LHtLYq+Mqd84VUecfAtAyBO4dcbR2eCaxbnoT6HG13VOuKA3KfYOY6S31RnIinDNBbiJBuGaiQXSWvQHo0haHEJcbWlaFkSkqSepGR/YZGP0PPy+eLjN1Zu/Kc/GlxVimtY2r823KBaMHGE+uRbgkQCSTxS6iy2oo5vOb20JbW2badil6kep5BnTibypDrVXdtHJUi2pVHs2BcMWzqJYUq4qmUp+Kt9SK04bPJU9ojJKUkS0rNJKcUaSLaYbvm+wT5RjeRyxpNZN7i3Gkj0M9Pt01Mukcg0SoNzZEv7iSxfmhN6Ipi69w/vXU5S2aYytlonFQHHYqVr1XtU86hzeZmpPJkkuhRig0jP8AkmXhfhcvCRWox1jKFxUWn3GvuRoilR5FNlvvEhGmjerjTR6oIjL7C+0BtYA8/m+JviYtvAtQzpcl7UeeVyXY/Ydp0qPbBvHEdOsPRvpGRyBm7JcQ2y6hEdpBEvY2Z71KPWs8MOZMtXHlms41u+r3LettJt1Fbg3ZV8eTLVcYnJkJafgLbdaQ06RpcbdbNJbiSThKNW3UBeb4zFiPGMmLCyTlO0LTkTkKditVyuRYC30JPRSkJeWk1ERmRGZa6DksXLWKsoHNTjTJlqXadNJs5pUKsxp/c3KbuT5TkVq2bti9N2mu1Wn2GNXuJVq4neM3HqbYwzQ8mzPq+rRnRaxUmILCEd3RNXyceZdTuSeiSTt1PefSWh65hUEZvoeEb4uuzsO2NhG8KIhuqRG48+DUoVYjRUqddZlOIjskylSOUQSjMjQaiVuItxGGzDz7EZpT8h5DTaf6lrUSUl5ukzHIPNnK2YspcVvBZk/OUS6I9q2PKqFLhUK3GokaXKJqPLZblLlvHqpC1yVpWhJbdrbKdSMndRfrLuniOrvEteuPpeWqOiycWQaBJqbsigsIlVt+VT1rcQbiTJMVpS0KdWokqNOqUo0LcA2oAaDY14rsty8l4x7uyoV8Ue/Lgeo1YagY/l0+3YP+zyHEFTKs+22uWpKmftVv5RJKURJIhm+F7z4tM02bavETQ8nWzDt28ayvWypdHZQ1TaGclxhLrU0jN12clCEubV/y1rPZogi6Q2uqN02xSF09urXHS4S6tNKmQEyJjbZy5hpWoo7RKMuUd2tuHsTqrRCj06DHaDzwwdVL1sGyMfIq1zQLjZr/ABDVikrKdQYpqiElyrm++wraZtuuuNEvcnRSCUpCT2mZDII/EHxIJwLTON2VkOld6dRrUZasd/QUfkkUR+qJgoSmcSu6DmkhaXTVuNG7VPJ+YBveA0cvbK/FXLonELk208uUSi0PC9w1BilUdy2WJKqm1EhR5TseS8pRKS3sdIkG2SXNy1GpZkSSLdK3KsVft6l10muSKpQmJezXXbyiCVp/+tQHYgAAAlWPv8XZkyBf6vCiUPuWyqWf9Ovc6e6Zrm37T3PyUNblGX/SeAlKTNx7Ncg3jAx7Y9evipI5SPQ6e/ONkjVufUhBmlpBJSpRrWrahKUpUo1KIiSozIj6rC9nT7Dxfb9t1lfKVdMdU2sOaJLlanKcVJmudCla7pDzytTUsz11Naz1UYZqAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlVX/wZxF0Otf0U/JFDct2Qo/s+lKabsyEhJF53Ir1WNaj80VovMQqomnEPSqlJxfOua34TsuuWVIj3bS2GE6vSHoDhPritn5jksIfimf+WSr7wFLAfJSarTa9SoVco01qZAqMduXFkMq3IeZcSSkLSfnI0mRkf3GPrABg+E8RW3gfFtAxJaE2pTKPbjLjEV+pOtuSVpW6t0zWptCEme5w/sSXRp/+RnAANeL14LbQuy47pqNMyfkC1aBfsop12WxQqkyxTqvINCUOuK3NKdZN5CUpe5JxPKEXmPpH03XwbWPclzXLWKZfl72xSL2hRYF0W9Q57EeDVmo0cozSVqUyp9ouQLk1E04jekiI/PrfgAQ20+E21LQmY3qMG/bvkScbW9ItKOt92IZVWjOGg0w5qUxyStDZNMkk2ybUZNluNR6meOWfwI2DaFTsqUWU8l1WnY4q30ralGqNXYdg0wtqy7nJJMEpxvRehGtRrSlKUpUkjXu2VABGH+FDGUrBruApU2vuUT6Tk1qLUSmIbqUGe7UHJ6ZDDzaEkhbT7p7D2n4JElW/VWv34k4fIWMrnql+1zI94X7dVVhNUs6tckpla40FtRrTHYbYbbbbQaz3qPaalK6TMVgAEdy7w0UjLN+0TJTOUb/smv0KlyKOxKtWfFjm5FfcQ44hzl47xnqptH2GX2Do5/CHCuKzKzj++eIDL910OvyITk+NVqxCUbrEdw1qiktqI2pLLxmknSSZKUlCUkpJGrdfgAQivcGuJ61DyVR4k64KJRMpxoiKzRqVJZYgx5cfZyc6I3yRmxIPk29xkZoXsSakGZajKrNwFa9q1G8axUa9Xbmm39TKbS6+7WHWFd1ohxFRSXoy02SVuIWo3PMaj8Ekl0CmgA1oo/AxbFI7ykKzZlCazjadHlWhHk1GGbFJZaI0dzk2mKSXkqaM2zW6S3EoIiQpGqt3ZW7wT43tuuUlca8LzetC3LgO6aFZDs9n6EplSN1bxOtoSyTykIdWpxDa3VIStRnp09GwoAIZRuEWxaLUYklm8LuehUy/3cjUymuyoxxoVRdTJJ1lv+Rv7nWqY6s0mo1akjRZERkrpafwP2DTpUKioyBezmPKZXiuSDj9UuMVFZmk+chKehgpCo6X1cqTBumjf9pGXQNjQASl/hvseRZWVrEXVa6UDMFQqFRrjhPs8tHdmRGorpRT5LahJNsINJLS4ZKNRmZloRUmiUmNQaNAocNbi2KdFaiNKcMjWaG0EkjUZERGehFroRD7QAAAAEqzR/im5LBxIjwmrgrB1urNn0pXSqWaJDiVpLwlIXKXT2lEe1BpeMlmolE07VRKsff4uzJkC/1eFEofctlUs/6de5090zXNv2nufkoa3KMv+k8BKUmbj1VAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAASrh3/3BbFaxK54K8a1yRbsVBf0ppZpRKpaE+dRNwJURk1edxhwvMYqolV32vlOgZQdyPieg2pW0V2hsUiuwK9X5NJJK4j7rkN9hbEKVvM0y5aHCUlJmSWNFHtMg74+Kf1N4q6y6j2EAqoCVd8fFP6m8VdZdR7CDvj4p/U3irrLqPYQCqgIVU8s8SVJvWg2HIwnjVU+4Yc+bFcRkiebKERDYJwlmdDJRGfdKNuiTI9FamWha5B3x8U/qbxV1l1HsIBVQEq74+Kf1N4q6y6j2EHfHxT+pvFXWXUewgFVASrvj4p/U3irrLqPYQd8fFP6m8VdZdR7CAVUBKu+Pin9TeKusuo9hB3x8U/qbxV1l1HsIBVQEq74+Kf1N4q6y6j2EHfHxT+pvFXWXUewgFVASrvj4p/U3irrLqPYQd8fFP6m8VdZdR7CAVUBKu+Pin9TeKusuo9hDH6/lniSty47YtidhPGq5V2TJEKEtrJE8221sxXZKjcM6GRkRoZURbSUe4y6CLUyC6gJV3x8U/qbxV1l1HsIO+Pin9TeKusuo9hAKqMfyDeMDHtj16+KkjlI9Dp7842SNW59SEGaWkElKlGtatqEpSlSjUoiJKjMiPCu+Pin9TeKusuo9hDqq7QM+5Oeo1sX7ZGP6BardYh1KsuUu8ptUkS2IrnLoilHcpcZKkOPNskvV4i2byUlxJqbUGa4Xs6fYeL7ftusr5Srpjqm1hzRJcrU5TipM1zoUrXdIeeVqalmeuprWeqjzUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABKr08o7F/wCH7o/upgqolV6eUdi/8P3R/dTBVQAAAAAAAAAAAAAAAAABKsqeN7C34gqv6JOFVEqyp43sLfiCq/ok4BVQAAAAAAAAAAAAAAAAAAAAAQrLOPbByVxJY3oWRrHt+6qaxY94S2odbpjM5ht9M+3kpdS28lSSWSVrSSiLXRai85gLqAlXNO4WPZpxV8G075Ic07hY9mnFXwbTvkgKqAlXNO4WPZpxV8G075Ic07hY9mnFXwbTvkgKqAlXNO4WPZpxV8G075Ic07hY9mnFXwbTvkgKqAlXNO4WPZpxV8G075Ic07hY9mnFXwbTvkgKqAlXNO4WPZpxV8G075Ic07hY9mnFXwbTvkgKqAlXNO4WPZpxV8G075Ic07hY9mnFXwbTvkgKqAlXNO4WPZpxV8G075Ic07hY9mnFXwbTvkgKqA1/pGJ8WYv4p7K+rPGlqWl9J4/u3u36Co0aB3VydRt7k+V5FCd+3lF7d2um9Wn2mNgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAASq9PKOxf+H7o/upgqolV6eUdi/8P3R/dTBVQAAAAAAAAAAAAAAAAABKsqeN7C34gqv6JOFVEqyp43sLfiCq/ok4BVQAAAAAAAAAAAAAAAAAAABKrj8qfHnu/vL9RtwVUSq4/Knx57v7y/UbcAVUAAAAAAAAAAAAAAAAAAAAAABKrj8qfHnu/vL9RtwVUSq4/Knx57v7y/UbcFVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABKr08o7F/wCH7o/upgqolV6eUdi/8P3R/dTBVQAAAAAAAAAAAAAAAAABHM61Q7avfFN4SqFcdQpdGr1QXPXRKBOq7sdDtJltIWpmE066STccQndt0I1FqZCxgAlXOWx16OZV6p7q7ODnLY69HMq9U91dnCqgAlXOWx16OZV6p7q7ODnLY69HMq9U91dnCqgAlXOWx16OZV6p7q7ODnLY69HMq9U91dnCqgAlXOWx16OZV6p7q7ODnLY69HMq9U91dnCqgAlXOWx16OZV6p7q7ODnLY69HMq9U91dnCqgAlXOWx16OZV6p7q7ODnLY69HMq9U91dnCqgA80eKD+ILkbhlzxCrVlM1m6se3VCRKl2veFs1SgyafKbPk3TgyJkVpwm3EpQotSfQlfLFsRqnW6cP/FJZHFbmrH99WVb9y0huNYd4R5TFXprjKCd+kbdIyYkkRsSSI0q15NZqSW3lENmtJHm1z8EeH8m5um52zXGdv2qk2zEo1JqSCKkUmG0XgNJjFry5mpTq18spbaluqNLaOgZTWIkWBxOY2gwYzUaNGx3eDLLLKCQhtCahbZJSlJdBERERERdBEQDos1OzrwzpjbCtSuetUO17go9erc9NHqb9NlVWTCVCQzE7qjrQ822SZbzq0trSa+TSRntJRHjFSue9MR1mi4dwrfUS9Z9wXq/RNt6TZU5VstlRV1FUdcklm/J2paJ1KXFmva+lBrSW1SbdkrEtjZZgQIV6U2U45SZXd1NnQKjIp86BI2KQbjEqMtt5ozSpST2qIlEZkZGXQPhtjBGK7PaoCKDbK2nLaqkutwJD1QkyJB1CTHdjyJL7zjilyXVtPuJNTyln0kZaGlJkEdt/iUy/MkWxeNRtK2JNo5Bq1bo1uUmGt5usRnYUac+w5KecWbKieTTnSWlLaORNxGq16KHRULiszRUbIuGY5a9Gk3PS36Mb9Mj2xWGqjQ2JinikLlUl0ykTUMciZodiOGl8uUNJIJs9bbTuGjDVMuOo3MzbMp56pnUVOQpVXmSKcwufu7tWxCcdVHYU/uXvU22kzJai+xSteujcJeE4tGfo6KXcTjjqoJtVN+66q9U4ZQlOHERGmrkG/HQ1y721DS0p0dXqR7lah01l8Rbd3WFTGanHmza/XKfVDTVbXoNUcorS4zklrVyS4yXcLv8As+qo8hSXG1nsM1eCpUf4be/qFiq0cu12yctPzWbEbuBdfr2VZVSpNRknS+V5VymnUF6oeUo1JQpkthqSeiDSWm29p46tCyLSOx7bpbjFIWqS48h2U9IefckuLckOuvurU664444tanFrNRqUZmYwK1+EzCVmtRYlv0+7WYUOEunMU96+69JhIiqZUwbJRnZimdhNqNKS2aJ0I06GkjIILfPELxNqsiOxJkWPQKtcVDti7KVKpkWW6cOPKq8SLIhvk46XKq/2pr+YnYRoN1O0j2rLNqhxCZ7Os1uk0u3bHSh2/kY5t1+QUs903kCkvTpaUr8FhDKHkpaSoluOEgtyCMtbFcHD/iW6KW3R6za7jkdihM22ybVSlMuM09l5p5ptDiHCUlaHWGVpdI+UI0F4X2j91jA+MK5a9VtCdQ5ZQazVk16S4zVZbUsqkk2zTKbkpdJ5p0jabMlIWn7D+89QiVJ4guIi68iM4Wt6k4+i3RTnbkjVerzY81VOeVTfopbL0ZhLpOElxFVQhbanFG2tKzJa+T2r4KPxk3bXaJB7jtWjtV28qVak6zopqdcZku1KUqJPQ4slFyqIjrTrxqRs1ZU2fn1PM61wb46qt22pMacrEW37cpNejPNR7iqbNTmT6lJhOuSXZ7b5SHdyYz6HCccVvJ4iPoLo74+HehLy3j29GqbQoFu4nocymWpTYkRZPsOym2mVKWs1bSabZaNKEEkzM3TUai2lqHJflcrcPibxJQIlYnMUypUC7HpsJuQtLElxk6ZyS3GyPatSOUc2mZGad6tNNTGIZmz/AJUs+uZFnWNRLVXbWIKDFr1worHL921flWnX1sQ1NrShjawyejjiXSW4rZtLaahUcl4PxxlyoUWr3tT6uufbyJTdNl0u4KjSX2ESeT5dPKQn2lKJXItakozLwejTp16Cfwq4VqkmnyqhRq9IVAiMwHCeumquFUYzL632mZ+6QfdyEOuLUkpHKabjT/T4IDA18SeS42aZ1k1C2KRT6Up6dHo1NqUGbDmVdLEBclt6LUlboDy1uNqbXFPk3WkktalHsNJ5Fwy5vvXLEi4KVf7NFg1akxoEtdMYpNRpNQp5yOWJbEqLN1NaUKa0RKaWpp7w9Eo2dOTP8NWHZd2Trwn23MmSahJkznoMmsTXaYmXIjrjyJKICnTioecZdcQpxLZKMnFnrqpRn2mM8JY+xK5Lk2fDqqpc2NGguy6tW5tVkFEjm4bEZDst1xbbLZvOGltJkkjWo9NTMwGDZZvii2BxJY3rNdhXBKjvWPeEZKKJb1QrL5LOfbyiNTMFl51KNEHqs0kgjNJGZGpJHkHOWx16OZV6p7q7OC4/Knx57v7y/UbcFVASrnLY69HMq9U91dnBzlsdejmVeqe6uzhVQASrnLY69HMq9U91dnBzlsdejmVeqe6uzhVQASrnLY69HMq9U91dnDILBzDZGSqrVqFbR3AxUqJHiS50Ot2zU6K+2xJU+lh1Lc+OypxC1RZCSUglFq0oj0GaiVW55U+Q/d/Zv6jcYCqgAAAAAAAAAAJ/eOdMf2NdS7Kq6Lrm1pmnx6o9GoVnVitchFfcfbZcdXBivIb3riyCSSjJR8ko9NOkdVzlsdejmVeqe6uzgFVASrnLY69HMq9U91dnBzlsdejmVeqe6uzgFVASrnLY69HMq9U91dnBzlsdejmVeqe6uzgFVASrnLY69HMq9U91dnBzlsdejmVeqe6uzgFVASrnLY69HMq9U91dnBzlsdejmVeqe6uzgFVASrnLY69HMq9U91dnBzlsdejmVeqe6uzgFVASrnLY69HMq9U91dnBzlsdejmVeqe6uzgFVASrnLY69HMq9U91dnDCr1/iCcKWNaq1QsjX3cFq1J+OmW1DrdjV+C+4wpSkpdS29CSo0GpC0koi01QovMYDYoAAAAAAAAAEqvTyjsX/AIfuj+6mCqiVXp5R2L/w/dH91MFVAAAAAAAAAAAAAdfXrhoFrUxdaueuU+kU5pxplcufJRHZSt1xLTSTWsySRrcWhCS11NSkkWpmRAOwAcMSXFnxWZ0GS1JjSW0vMvMrJaHEKLVKkqLoMjIyMjLoMjHMAAAAAAAAAAAAAAAAAAAAAAAAAlVx+VPjz3f3l+o24KqJVcflT489395fqNuAKqAAAAAAAAAAAAAAAAAAAAAAAlVx+VPjz3f3l+o24KqJVcflT489395fqNuCqgAAAAAAACVW55U+Q/d/Zv6jcYqolVueVPkP3f2b+o3GAqoAAAAAAAAAJVbnlT5D939m/qNxiqiVW55U+Q/d/Zv6jcYqoAAAAAAAAAAAAAAAAAAAAAPFb+NX5U9re7+D+o1Ee1I8Vv41flT2t7v4P6jUQHtSAAAAAAAAACVXp5R2L/w/dH91MFVEqvTyjsX/AIfuj+6mCqgAAAAAAAAAAAknFDEiz8YU6DOjNSY0m/LGZeZeQS0OIVdNLJSVJPoMjIzIyPoMjFbEq4lvF1SPeBYn7qpYDll8O9hRZT1Tx/LrePKjIcU84/ac3uNlxaj3GpcJaVwnT5TVzVxhRmpTmupOukvi/wCI6zfRXJEBP/voNULd/wDdGe2q/wDg8BXnU3/OqoAJfE4iLCiymaZkCJW8eVGQ4llti7IXcbLi1HtJKJqFLhOnymjejb6jNSm9NSdaNdKiS4s+KzOgyWpMaS2l5l5lZLQ4hRapUlRdBkZGRkZdBkYS4kWfFegzozUmNJbUy8y8glocQotFJUk+gyMjMjI+gyMTWXw72FFlPVPH8ut48qMhxTzj9pze42XFqPcalwlpXCdPlNXNXGFGalOa6k66SwqACVf8R1m+iuSICf8A30GqFu/+6M9tV/8AB4CvOpv+dyxOIiwospmmZAiVvHlRkOJZbYuyF3Gy4tR7SSiahS4Tp8po3o2+ozUpvTUnWjWFQAcMSXFnxWZ0GS1JjSW0vMvMrJaHEKLVKkqLoMjIyMjLoMjHMAAAAAAAAAAAAAAAlWS7Xyn9adoZMxnQbUrf0Jb9eoU2FXa/JpX/AF0mlvNutOMwpW/b9HLSpKkp/wCYkyM9DIVUAEq74+Kf1N4q6y6j2EHfHxT+pvFXWXUewhVQASrvj4p/U3irrLqPYQd8fFP6m8VdZdR7CFVABKu+Pin9TeKusuo9hB3x8U/qbxV1l1HsIVUAEq74+Kf1N4q6y6j2EHfHxT+pvFXWXUewhVQASrvj4p/U3irrLqPYQd8fFP6m8VdZdR7CFVABKu+Pin9TeKusuo9hB3x8U/qbxV1l1HsIVUAEq74+Kf1N4q6y6j2EHfHxT+pvFXWXUewhVQAR+27bzRX80UPI2RrVsq36bb9r1uiNNUS6JdWfkvz5dLeSpSXqdFS2hCacsjMlKMzcT0FoZiwAAAAAAAAAAlVueVPkP3f2b+o3GKqNX83X/mHDGeVXLjnAMvI68j0e37UpSE3LBpDBTYHfFUJLa3HzUsllHWhadWibUROFyhLSlCw2gAaq84fjs/7dX/l2j/LDnD8dn/bq/wDLtH+WA2qAaq84fjs/7dX/AJdo/wAsOcPx2f8Abq/8u0f5YDaofPAqNPqsVM2mTo8yOpS0JeYdS4g1JUaVESkmZakpJkf3GRl5hq09xBcc0hpbD/8ADlQ404k0LQvLdGNKkmWhkZG10kZDyat3MnFBgPiUuq3sJLuSg3BLuWW0/ZUWolcqFvk6rWG6SCW3NdbSRtG6lPKltVoaVa6B7e255U+Q/d/Zv6jcYqo1d4ULszbe2U7xuDiBxxTLJu5+wbP5amQJxyEKZ+kLi2PKQe7udSjNX8k3HTSRJ3KJRqQjaIAGGXdmrD1gV6Fa185UtK3qzUSScSn1Ssx4sh4lHtSaW3FkoyNRaEemhn0F0jMxp1T8l4WxVVeIC0uIE6Wi4LguaXPRSKilLky7KO/DYRAZhNq8KWW1KoyWm9xpWhRGSTUA3E+3pIf0aI1O+q3TbzqdMTkavWpkij3ZadFsnG6a2ruVdAeapvLEuHrtnI2O1HlpSiUbRx1GlSOT8Lmsq3L6vu5LAXWM8ZNYj3zcF+wqxFhXE6w33JTqhJTCZjmnwoxt8kjVxsyWotUGo0GSSDdyPWaRLqcyiRarDeqNPQ07LiNvpU9HQ7u5JTiCPcgl7F7TMi12q010MKdWaPWDlppFVhzjgSVw5ZRn0u9zyEERqac2mexZEpOqT0MtS6OkeYdPydNqVAq9+V7PNxUHKMvE9nVC1IMCp9yruWv8lMJCXGC8GepbpsoUyZKSSX1qNPSSk3KkIvjKWelY3rOUbxoNLcqN+Oy2rerLsJTioqqAiOgnE+ESWlS3VJ00PpNJ6pWtKg3WHw1CuUWkyqfBqlYhQ5NXkHEp7MiQhtct8m1um00lRkbiybbcXtTqe1Cj+wjMeaNSz7nSuUC16pVcpRaBWHMZWtVbWcnXZLpR1aryGnO6ZKKdFgSfpxxTyW21xTMiSnTagjd3p214pLxtuw7rwLd9/XBTKDSYF+PqnT5slLMZg12/VUFucXoREa1JSWv2mZfeA2HAaY5uzljm8bwTUz4lHrcsBuyps+2albFylDaq1xNPrS+zyzStJTrLZRTbimaiWby9UL00GMWzlbJcbOVqtZDyLNmXDNcoUOfbVJr7sWZSpD9GYVKadoDrPJT4Rvm6/wB2tL5Rs1KRqRNGkBvqA074Ish1q4rtq1ArOSpd8yXLdi1KTVYd0O1WnuvE8aDW9EfaQ9RZqtfDgl/LLYrQiNBjcQAHit/Gr8qe1vd/B/UaiPakeK38avyp7W938H9RqID2pAAAAAAAAABKr08o7F/4fuj+6mCqiVXp5R2L/wAP3R/dTBVQAAAAAAAAAAASriW8XVI94FifuqliqiVcS3i6pHvAsT91UsBVQAAAAAAHDLiRZ8V6DOjNSY0ltTLzLyCWhxCi0UlST6DIyMyMj6DIxzAAl8vh3sKLKeqeP5dbx5UZDinnH7Tm9xsuLUe41LhLSuE6fKauauMKM1Kc11J10l8uGLlvKqTsgWne1biVmXZN0N0SPUmYJRFy2HKRTp5KdbSpSCWlc9xsjTtI0No1LduUdLEqw34xc7e8CH+1aCAqoAAAAAAAAAAAAAADFMnZCh4vtBy7ZtBqtb/3hTaXHp1L5DuqVKnTWIUdtByHWmi1ekt6mtxKSTqevQAysBKvrkyL7J2VfzK1e2Q+uTIvsnZV/MrV7ZAVUBKvrkyL7J2VfzK1e2Q+uTIvsnZV/MrV7ZAVUBKvrkyL7J2VfzK1e2Q+uTIvsnZV/MrV7ZAVUBKvrkyL7J2VfzK1e2Q+uTIvsnZV/MrV7ZAVUBKvrkyL7J2VfzK1e2Q+uTIvsnZV/MrV7ZAVUBKvrkyL7J2VfzK1e2Q+uTIvsnZV/MrV7ZAVUBKvrkyL7J2VfzK1e2Q+uTIvsnZV/MrV7ZAVUBH5/EDX6A5TXrv4c8lW/TajWKZRDqUuXbzzEZ+fNZhx1OJjVV140ctIaIzQ2oyIzPToFgAAAAAAAAEqzJ4xcE+8CZ+1a8KqJVmTxi4J94Ez9q14BVQAAAAABwy2XJMV6OzLdiuOtqQh9kkGtozLQlpJaVJMy+0tyTLUukjLoE6wxw5YbwDAfjYxsqJT5s7VVRq76lSanUVmrcpUiW6anXNV6q2mrYRme1KfsFLABKrc8qfIfu/s39RuMVUSq3PKnyH7v7N/UbjFVAB+FssuOIdW0hS29TQo0kZp1+3Q/MP2AD8GyybqXzaQbqUmklmktxEf2kR/d0D9gAD8qbQs0qWhKjQe5JmWu09NNS+7oM//AOj9AAD8LZZcWhxxpCltGZoUpJGaTMtNSPzdA/YAA/DjLL203WkL2KJadySPaovsMvuMORZ5bujkkcrt2b9pbtuuumv26a+YfsAH4bZZZ38k0hG9RrVtSRblH9pn95/+o/YAADxW/jV+VPa3u/g/qNRHtSPFb+NX5U9re7+D+o1EB7UgAAAAAAAAAlV6eUdi/wDD90f3UwVUSq9PKOxf+H7o/upgqoAAAAAAAAAAAJVxLeLqke8CxP3VSxVRKuJbxdUj3gWJ+6qWAqoAAAAAAAAAAlWG/GLnb3gQ/wBq0EVUSrDfjFzt7wIf7VoICqgAAAAAAAAAAAAAlXEt4uqR7wLE/dVLFVEq4lvF1SPeBYn7qpYCqgAAAAAAAAAAAAAAAAAAAAAAJVxLeLqke8CxP3VSxVRKuJbxdUj3gWJ+6qWKqAAAAAAAAJVmTxi4J94Ez9q14VUSrMnjFwT7wJn7VrwCqgAAAAAAAAAlVueVPkP3f2b+o3GKqJpduGJ1fv8AmZGtrMF62XUqjR4NEnNURmkPMSWIb0t5hSkz4MlSVkqdIIzQpJGRp1Lo1Hy/U3kX2scq/ltq9jAKqAlX1N5F9rHKv5bavYwfU3kX2scq/ltq9jAKqAlX1N5F9rHKv5bavYwfU3kX2scq/ltq9jAKqAlX1N5F9rHKv5bavYwfU3kX2scq/ltq9jAKqAlX1N5F9rHKv5bavYwfU3kX2scq/ltq9jAKqAlX1N5F9rHKv5bavYwfU3kX2scq/ltq9jAKqAlX1N5F9rHKv5bavYwfU3kX2scq/ltq9jAKqPFb+NX5U9re7+D+o1Eeqn1N5F9rHKv5bavYwima/wCGfjHiJuqLeuY805VuCtQqeilsSeWosTZFQ444lvZHpraD0W84eplu8LTXQiIg3AAAAAAAAAABKr08o7F/4fuj+6mCqiVXp5R2L/w/dH91MFVAAAAAAAAAAABI+KRxbOLae82ei0X3Y6knp9hldFM0HRcUHFXT+FFy2LlvyyanUrEr8pdMm1mlrSt+kzdN7JOR1acq04gnD3JWSkcirwVmtJF0+Tcy4szxgmnXNiG+qVc9PcvuxULVDe/mx1quimbUPsr0cYWZdOxxKVadOmgCLYl4wcrZ8x3jfCmJL1pc7MdwUFNavO65EaMqPbEFL21b3cqUk09LUSm0oYJG0t6VLIiPUZbTOIHLVocezmELrvJ6s45VSKVQmnJcGG06ivSoD0tl9bjLKDNTxU+WnYRk2SnC2oLQtMZs7guvzHvC9jC5MZWjT7Vz9jMnKuTCH4+2tPOrMplNmPoWbbqH2iSklG5og0oIlITqZd1fuBc2ZDrGZ8mw8fLoFzVan2FctkRpVThOrTX6MUl52IpbbxoSZLWTBuKUltRPGaVaEZkHbU7iTyTcH8QF/FsC4WY+KaVSqlS32DjR9kmswY0aTKeN9SOVSTZT2GzSSyTq2rwftM6RZfGjia97lodFhUW9KfSbsnrpls3PU6C5GotdlJStRNRZBnqZrS2s0G4hBL2mSTMy0EeszhQyi2/jBVy04o0+oWnfbl+VVqUwpUKu3AbDpltS5udNKzcbJTe5OjBaq6SM8PwpwyZPgT8U2FeWCLliOY8q8CfVrkrGTJs+31fR/SxIplObmdDrikoNCFsobaJSkqQZHtAbIM8aOK37lj0hNu3uVCl3GVpRruVQVlQn6scg43c6JG7cZcuk2+V2cluIy39Bjr7u46cT2fWLvpcm0Mh1KPYFSOnXTU6Zbq5EGjkSUGT7zxLIjbMln0IJThEhRmgk6Ges9zYE4n7hh02p3jiW9rwvu2L7i3LPrUq/2U0eXBj1MnkM0emHLJltao+wtr7beza54ZrMiO6zMIZOk4U4qrXRaelYyZXa9OtmMc2NrOZk0iIwwZr5TY1q804nRxSTLTU9CMjMM5yJxjYwx3X6xRHLevS42LWYiSrnqlvURU6FQGJLXKtOS1kolERtfzDJtLikoMlGREY7zCUliZfucZcV5LrL9+wnG3EHqlaTtSgmRkfnIyMau5hwfmNFwVWqWPhC6YV9TLfpcO3L6sS72qSRyWITbXI1xh2UTb6GXkqLelte9kkoLQy1KwYtoHEEu+Mus27k+xYTke66WxVFVazJVRclVBNqULln21s1KKlttXg6N8mZkZGe4yMkpDZwBKu9zin9cmKurSo9uh3ucU/rkxV1aVHt0BVQEq73OKf1yYq6tKj26He5xT+uTFXVpUe3QFVASrvc4p/XJirq0qPbod7nFP65MVdWlR7dAVUBKu9zin9cmKurSo9uh3ucU/rkxV1aVHt0BmlbyHY9tXNRbNuK6adS6zcZO/Q8SY+TKqgps0kttg16E64XKIM20ma9D1006RhfEt4uqR7wLE/dVLGl38Umk5XqGH7Xx3ely2fe9x3NcKDtiiWxYM+LVlvMNKN55lR1WRuQlDiW1oJlZny6DIiMtyfhwTi/jzsPEtAPiIv+ImzO/ixSh23WzOp1tn/FFL5M0ykrLuZBeBo24t/RKVI5Jkz3EHpoAAADAa5nbFFt0Wv3BWbtRHh2zWk25UNIkhbv0opDS0RGWUtm5JdUUhrallKzUatC1MjIs+GjVRxFk60sr31xP0qj3HcK7RyPJlxrLdp+9qoUZ+mQmZk6mNmje5OLpNtxCj3lFWynpWrUNsrSzFje+K1dlu21czcipWM+1HuGM7Hejrp63WjdRv5VCdSNBKPcnUi2qIzIyMi+nF2UbFzRYtMyXjSulWbbrPLdxTe5no/K8k8tlz+W8hDidHG1p8JJf06lqRkY0tubHWV277v6u2PZFyojZnumbYtXlFTH2HIlJlMU5xirr3pJTbUdr6YQSzLQnX0p6FdAwWt4nyFRqDblAr1nVeHaEOJecaiU5VhVevHFqj1zT3GVtR4MqMqI+5EXFVGlPGbZJ3GlSN24w9NgHnXdNEyxByfb9brdo3O9ctrVyx0y6wmzatUalUKY03TyqctFQYeXChx1bpaHoTKX3FrS6pRmR7ypGJMN1W0b0xRkOPZdwRLiql+3vHuqoPMyuU+h3PplyGiSSuhuMbjUA2dxEjctBp6XNVBtjEvS2p15VOwItS31+j0+JVJsTkXC5KLKW+2w5vNOxW5UZ8tEqNRbOkiI0692NcK7epYs4qryua4bHv6oUmu2TbkOFOoFnVOsMLfjzKqp5tTkNhxKFJTIZPRRkeiyEqK1ajU8tuVFiyb4TleRkxusM3Muiz2YyLO3coUYpi0lGbZ7h1iqjKWSu6Vbjb3FqQbyAPNuzbAuCHjq87dj2tfTcCTSaKup3CzY1Ui1dUliptKXHq1Ode5Otupb3nJfhK1eYJ1Ja70Ee23CBBqdLxGumTrQRb0aNWpyacyzBnU+NJiGslIkR4M4zkQmVmpe1hZ6J0M0+CpIC3AAAJVxLeLqke8CxP3VSxVRH+KxuqvYliM0KbEh1Jd8WQmHIlxlSWGXzuimcmtxpLjanEErQzQTiDURGRKTrqX197nFP65MVdWlR7dAVUBKu9zin9cmKurSo9uh3ucU/rkxV1aVHt0BVQEq73OKf1yYq6tKj26He5xT+uTFXVpUe3QFVEqzJ4xcE+8CZ+1a8He5xT+uTFXVpUe3R8iMX5or972TcuRsp2VUabZdYkVtqDRLJl05+S+5TJsBKVPvVSSlKCTOWsyJozM0JLUukBYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABiV94ox/kt2nv3vbyKk7S0vIiLOQ80ppLpoNwiNtadSUbTeuuv9JDF+a5gr0G/1OZ80VUAEq5rmCvQb/U5nzQ5rmCvQb/U5nzRVQASrmuYK9Bv9TmfNDmuYK9Bv9TmfNFVABKua5gr0G/1OZ80Oa5gr0G/1OZ80VUAGlHGRwQv5Ys+h4vwVZNHo6qxUik125qtVH3GaXDj6KJttlS1uLfeWotpoQaSSy4lakb0mMXoH8OzDXClZNCvGn1Gq3RfJXxY8dyuTHVR2m0Luilk4hiI2rYhCiIv+YbqyMuhZF0Df8SriW8XVI94FifuqlgKqAAAAAAAAAAJVhvxi5294EP8AatBFVEqw34xc7e8CH+1aCAqoAAAAAAAAAAAAD5PomlfSv079GRPpLufuTuzkU8vyG7dyXKabtm7wtuumvSJrxLeLqke8CxP3VSxVRKuJbxdUj3gWJ+6qWAqoAAAAAAAAAAAAAAAAAAAAAACVcS3i6pHvAsT91UsVUSriW8XVI94FifuqliqgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlXEt4uqR7wLE/dVLFVEq4lvF1SPeBYn7qpYCqgAAAAAAAAACVYb8YudveBD/atBFVEqw34xc7e8CH+1aCAqoAAAAAAAAAAAAAJVxLeLqke8CxP3VSxVRj9+WHbOSrZftC74st+mvyIksyiVCRBfbfjSG5Md1uRGW280tDzLSyUhaT1QQDIAEq5tOOvSPKvWxdXaIc2nHXpHlXrYurtEBVQEq5tOOvSPKvWxdXaIc2nHXpHlXrYurtEBVQEq5tOOvSPKvWxdXaIc2nHXpHlXrYurtEBVQEq5tOOvSPKvWxdXaIc2nHXpHlXrYurtEBVQEq5tOOvSPKvWxdXaIc2nHXpHlXrYurtEBVQEq5tOOvSPKvWxdXaIc2nHXpHlXrYurtEBVQEq5tOOvSPKvWxdXaIc2nHXpHlXrYurtEA4lvF1SPeBYn7qpYqolSOGbF3dkCbNmZAqf0ZUIdUjx6pke4p8XuqK+iRHcXHkTltO7Hmm1kS0KTuQXR0CqgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlXEt4uqR7wLE/dVLFVEq4lvF1SPeBYn7qpYCqgAAADH7zyFYmOaa3WL/vKiW5CecJlp+qTmoyXXD+xtBuGW9Z+ZKdTPzEMK+ue57p/lYlw5ctcQvoRVbiQq26WlX3KOU2c5RGXSS2YbrZ/wCbzgKqMfvPIViY5prdYv8AvKiW5CecJlp+qTmoyXXD+xtBuGW9Z+ZKdTPzEMK+r7Mt4eHkLMH0FCX0qo9jwUw9UH/U09UJPLSHNPsJ2MmGvz6EMgszC+L7AqTletq0Iia482bL9dnLcn1eQj/K9Pkqckul9xLcURAMf+ue57p/lYlw5ctcQvoRVbiQq26WlX3KOU2c5RGXSS2YbrZ/5vOO1xJYt1Wk7eNw3rVKVKrV8XAivyY9LYcRFgbabCgojoW4o1vaIgJUbppb3KWejaCIiFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABH+Kyq02g4liVyszWocCnXxZEuVIeVtQyy3dFMUtaj8xEkjMz+4hYAASr657nun+ViXDly1xC+hFVuJCrbpaVfco5TZzlEZdJLZhutn/m84fV9mW8PDyFmD6ChL6VUex4KYeqD/qaeqEnlpDmn2E7GTDX59CFVABhVmYXxfYFScr1tWhETXHmzZfrs5bk+ryEf5Xp8lTkl0vuJbiiIZqAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//Z"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "\n",
    "The goal of the project is to create a semi-supervised learner. Our training data is comprised of a small small batch of labelled data encorperated with a larger set of unlabelled data to create a stronger learner. In this project we will observe the impact of increaseing the presence of unlabeled data has on the error rate.\n",
    "\n",
    "We use the label data to extract deep feature from a CNN we repaat a process of Convolution, followed by ReLU and Max Pooling three times. Before the final fully connected layer we extract the feature map and then apply kmeans. we rectify the losses to encourage the learner to create features who create distinct clusters (measure of distance is L2 norm).\n",
    "\n",
    "\n",
    "![learner-arch .jpg](<attachment:learner-arch .jpg>)\n",
    "\n",
    "\n",
    "WE experimented also with how often we ran Kmeans we followed the heuristic that the more amount of unlabeled data the more we will run kmeans. We want the impact of the weight to proportional, we have two examples one *insert ratios we have picked.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Member and Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Libraries\n",
    "\n",
    "\n",
    "| **Libraries**      | **Explanation**                                                                                  |\n",
    "|---------------------|--------------------------------------------------------------------------------------------------|\n",
    "| **NumPy**           |  Library for numerical computing in Python, providing support for arrays, matrices, and mathematical functions. |\n",
    "| **Matplotlib**      | 2D plotting library for creating static, interactive, and animated visualizations in Python.  |\n",
    "| **Scikit-learn**    | Used for implementation of KMeans algorithm |\n",
    "| **PyTorch**         | Another deep learning framework, known for its flexibility and dynamic computation graph.         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# importing essential libraries for basic image manipulations.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as tF\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      (\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Preparation\n",
    "  - Load CIFAR-10 dataset with transformations.\n",
    "  - Split training data into labeled and unlabeled subsets.\n",
    "  - Create dataloaders for labeled, unlabeled, and test data.\n",
    "\n",
    "Step 2: labeled_labeled_model Definition\n",
    "  - Define a CNN with:\n",
    "    - Feature extraction layers.\n",
    "    - Fully connected classification head.\n",
    "  - Ensure labeled_labeled_model outputs:\n",
    "    - Features for clustering.\n",
    "    - Logits for classification.\n",
    "\n",
    "Step 3: Loss Functions\n",
    "  - Supervised Loss: Cross-entropy on labeled data.\n",
    "  - Unsupervised Loss:\n",
    "    - Perform K-Means on features of unlabeled data.\n",
    "    - Compute clustering loss (e.g., mean distance to cluster centers).\n",
    "\n",
    "Step 4: Training Loop\n",
    "  For each epoch:\n",
    "    - Train on Labeled Data (Supervised Step):\n",
    "      - Load labeled batch.\n",
    "      - Pass batch through the labeled_labeled_model.\n",
    "      - Compute cross-entropy loss.\n",
    "      - Backpropagate and update labeled_labeled_model.\n",
    "\n",
    "    - Train on Unlabeled Data (Unsupervised Step):\n",
    "      - Extract features for all unlabeled data.\n",
    "      - Perform K-Means on features.\n",
    "      - For each batch of unlabeled data:\n",
    "        - Compute clustering loss.\n",
    "        - Backpropagate and update labeled_labeled_model.\n",
    "\n",
    "    - Log losses and progress.\n",
    "\n",
    "Step 5: Testing and Evaluation\n",
    "  - Evaluate on test set:\n",
    "    - Compute accuracy using predicted labels.\n",
    "  - Analyze performance at different labeled/unlabeled splits.\n",
    "\n",
    "Step 6: Results Analysis\n",
    "  - Plot training losses.\n",
    "  - Visualize feature clustering with t-SNE.\n",
    "  - Discuss how unlabeled data improved the labeled_labeled_model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Preparation\n",
    "  - Load CIFAR-10 dataset with transformations. Use pre-defined transformations\n",
    "  - Split training data into labeled and unlabeled subsets.\n",
    "  - Create dataloaders for labeled, unlabeled, and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize RGB channels\n",
    "# ])\n",
    "\n",
    "# # Load CIFAR-10 dataset (original training set only)\n",
    "# full_trainset = torchvision.datasets.CIFAR10(\n",
    "#     root='./data', train=True, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "# # Split into 80% train and 20% validation\n",
    "# train_size = int(0.8 * len(full_trainset))\n",
    "# val_size = len(full_trainset) - train_size\n",
    "# trainset, valset = random_split(full_trainset, [train_size, val_size])\n",
    "\n",
    "# # Create DataLoaders for training and validation\n",
    "# trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "# valloader = DataLoader(valset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # Load CIFAR-10 test set (unchanged)\n",
    "# testset = torchvision.datasets.CIFAR10(\n",
    "#     root='./data', train=False, download=True, transform=transform\n",
    "# )\n",
    "# testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "def load_cifar10_datasets(root='./data'):\n",
    "    transform = get_cifar10_transforms()\n",
    "    trainset = torchvision.datasets.CIFAR10(root=root, train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root=root, train=False, download=True, transform=transform)\n",
    "    return trainset, testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_unlabeled_subsets(trainset, labeled_ratio=0.2, unlabeled_ratio=1.0):\n",
    "\n",
    "    # fix labeled portion at 20% of the training data (or possible to give another labeled_ratio)\n",
    "    total_size = len(trainset)\n",
    "    labeled_size = int(labeled_ratio * total_size)\n",
    "\n",
    "    indices = torch.randperm(total_size).tolist()\n",
    "\n",
    "    # labeled indices\n",
    "    labeled_indices = indices[:labeled_size]\n",
    "\n",
    "    # unlabeled indices\n",
    "    unlabeled_indices = indices[labeled_size:]\n",
    "\n",
    "    # from unlabeled pool choose fraction given by unlabeled_ratio\n",
    "    chosen_unlabeled_size = int(len(unlabeled_indices) * unlabeled_ratio)\n",
    "    chosen_unlabeled_indices = unlabeled_indices[:chosen_unlabeled_size]\n",
    "\n",
    "    labeled_set = Subset(trainset, labeled_indices)\n",
    "    unlabeled_set = Subset(trainset, chosen_unlabeled_indices) if chosen_unlabeled_size > 0 else None\n",
    "\n",
    "    return labeled_set, unlabeled_set\n",
    "\n",
    "# create dataloaders\n",
    "def create_dataloaders(labeled_set, unlabeled_set, testset, batch_size=32):\n",
    "    \n",
    "    labeled_loader = DataLoader(labeled_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    unlabeled_loader = DataLoader(unlabeled_set, batch_size=batch_size, shuffle=True) if unlabeled_set is not None else None\n",
    "\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "    return labeled_loader, unlabeled_loader, test_loader\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset, testset = load_cifar10_datasets()\n",
    "\n",
    "# Always 20% labeled\n",
    "# For the benchmark scenario: unlabeled_ratio=0.0 means no unlabeled data used\n",
    "labeled_set, unlabeled_set = create_labeled_unlabeled_subsets(trainset, labeled_ratio=0.2, unlabeled_ratio=0.0)\n",
    "labeled_loader, unlabeled_loader, test_loader = create_dataloaders(labeled_set, unlabeled_set, testset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to\n",
    "def get_device():\n",
    "    return torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                        (\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined Convolutional Neural Network\n",
    "# uses: \n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))  # [N,128,1,1]\n",
    "        )\n",
    "\n",
    "        self.classifier_head = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def feature_extractor(self, x):\n",
    "        x = self.conv(x)           # shape: [N, 128, 1, 1]\n",
    "        x = x.view(x.size(0), -1)  # Flatten to [N, 128]\n",
    "        return x\n",
    "    \n",
    "    def classifier(self, features):\n",
    "        return self.classifier_head(features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        f = self.feature_extractor(x)\n",
    "        logits = self.classifier(f)\n",
    "        return f, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute K clustroids\n",
    "def compute_kmeans_centers(model, unlabeled_loader, device, K):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for u_inputs, _ in unlabeled_loader:\n",
    "            u_inputs = u_inputs.to(device)\n",
    "            u_features, _ = model(u_inputs)\n",
    "            all_features.append(u_features.cpu().numpy())\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    kmeans = KMeans(n_clusters=K, random_state=RANDOM_STATE)\n",
    "    kmeans.fit(all_features)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    return torch.tensor(cluster_centers, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: labeled_labeled_model Definition\n",
    "  - Define a CNN with:\n",
    "    - Feature extraction layers.\n",
    "    - Fully connected classification head.\n",
    "  - Ensure labeled_labeled_model outputs:\n",
    "    - Features for clustering.\n",
    "    - Logits for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use t-SNE or PCA to show clusters in the feature space ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take in argument based on which we want to use, lets use c_e for now\n",
    "# def supervised_loss(logits, labels):\n",
    "#     return F.cross_entropy(logits, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, random_split\n",
    "# from sklearn.cluster import KMeans\n",
    "# import numpy as np\n",
    "\n",
    "# # Define transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# # Load CIFAR-10 dataset\n",
    "# full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# LABEL_SIZE = 0.2\n",
    "\n",
    "# # Split into labeled and unlabeled datasets (20% labeled)\n",
    "# labeled_size = int(LABEL_SIZE * len(full_trainset))\n",
    "# unlabeled_size = len(full_trainset) - labeled_size\n",
    "# labeled_set, unlabeled_set = random_split(full_trainset, [labeled_size, unlabeled_size])\n",
    "\n",
    "# print(f\"Labeled size: {labeled_size}, Unlabeled size: {unlabeled_size}\")\n",
    "\n",
    "\n",
    "# # Compute ratio\n",
    "# ratio = unlabeled_size / labeled_size\n",
    "\n",
    "# # A simple heuristic: if ratio is large, update K-Means less often\n",
    "# # For instance, if ratio = 1 means run every epoch, if ratio=5 means run every 5 epochs\n",
    "# kmeans_update_frequency = max(1, int(ratio))\n",
    "\n",
    "# print(f\"K-Means will be updated every {kmeans_update_frequency} epochs based on ratio={ratio:.2f}.\")\n",
    "\n",
    "# # Create DataLoaders for labeled and unlabeled datasets\n",
    "# labeled_loader = DataLoader(labeled_set, batch_size=32, shuffle=True)\n",
    "# unlabeled_loader = DataLoader(unlabeled_set, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Load CIFAR-10 test set\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # Define device\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "#                       (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# model = CNN().to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 10\n",
    "# K = 10  # number of clusters\n",
    "# lambda_cluster = 0.5\n",
    "\n",
    "# cluster_centers_torch = None  # will store cluster centers\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.eval()\n",
    "    \n",
    "#     # Update K-Means only every kmeans_update_frequency epochs or if we have no cluster centers yet\n",
    "#     if epoch % kmeans_update_frequency == 0 or cluster_centers_torch is None:\n",
    "#         # ----- Run K-Means Clustering on Unlabeled Data -----\n",
    "#         all_features = []\n",
    "#         with torch.no_grad():\n",
    "#             for unlabeled_batch in unlabeled_loader:\n",
    "#                 u_inputs = unlabeled_batch[0].to(device)\n",
    "#                 u_features, _ = model(u_inputs)\n",
    "#                 all_features.append(u_features.cpu().numpy())\n",
    "        \n",
    "#         all_features = np.concatenate(all_features, axis=0)  # shape: [num_unlabeled_samples, feature_dim]\n",
    "\n",
    "#         # Fit KMeans\n",
    "#         kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "#         kmeans.fit(all_features)\n",
    "#         cluster_centers = kmeans.cluster_centers_\n",
    "#         cluster_centers_torch = torch.tensor(cluster_centers, dtype=torch.float32, device=device)\n",
    "#         print(f\"Updated K-Means at epoch {epoch+1}\")\n",
    "\n",
    "#     # Reset unlabeled loader iterator for this epoch\n",
    "#     unlabeled_iter = iter(unlabeled_loader)\n",
    "\n",
    "#     model.train()\n",
    "#     running_supervised_loss = 0.0\n",
    "#     running_cluster_loss = 0.0\n",
    "    \n",
    "#     for x_l, y_l in labeled_loader:\n",
    "#         x_l, y_l = x_l.to(device), y_l.to(device)\n",
    "        \n",
    "#         # Get an unlabeled batch\n",
    "#         try:\n",
    "#             x_u, _ = next(unlabeled_iter)\n",
    "#         except StopIteration:\n",
    "#             unlabeled_iter = iter(unlabeled_loader)\n",
    "#             x_u, _ = next(unlabeled_iter)\n",
    "        \n",
    "#         x_u = x_u.to(device)\n",
    "        \n",
    "#         # Compute supervised loss\n",
    "#         f_l, logits_l = model(x_l)\n",
    "#         supervised_loss = criterion(logits_l, y_l)\n",
    "        \n",
    "#         # Compute cluster loss for the unlabeled batch:\n",
    "#         f_u, _ = model(x_u)\n",
    "        \n",
    "#         # Assign clusters by finding nearest center\n",
    "#         with torch.no_grad():\n",
    "#             dists = torch.cdist(f_u, cluster_centers_torch)\n",
    "#             assignments = dists.argmin(dim=1)\n",
    "        \n",
    "#         assigned_centers = cluster_centers_torch[assignments]\n",
    "#         cluster_loss = ((f_u - assigned_centers)**2).mean()\n",
    "        \n",
    "#         # Combine losses and backprop\n",
    "#         total_loss = supervised_loss + lambda_cluster * cluster_loss\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_supervised_loss += supervised_loss.item()\n",
    "#         running_cluster_loss += cluster_loss.item()\n",
    "    \n",
    "#     avg_supervised_loss = running_supervised_loss / len(labeled_loader)\n",
    "#     avg_cluster_loss = running_cluster_loss / len(labeled_loader)\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "#           f\"Supervised Loss = {avg_supervised_loss:.4f}, \"\n",
    "#           f\"Cluster Loss = {avg_cluster_loss:.4f}\")\n",
    "\n",
    "# # ----- Evaluation -----\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in testloader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         _, logits = model(inputs)\n",
    "#         _, predicted = torch.max(logits, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# from sklearn.cluster import KMeans\n",
    "# import numpy as np\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            _, logits = model(inputs)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# ---------------------\n",
    "# Training Function\n",
    "# ---------------------\n",
    "def train_model(model, labeled_loader, unlabeled_loader, test_loader, device,\n",
    "                num_epochs=10, lr=0.001, K=10, lambda_cluster=0.5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    # Determine how often to update K-Means\n",
    "    # If no unlabeled data, ratio=1 (just default) and we won't actually run K-means\n",
    "    if unlabeled_loader is not None and len(unlabeled_loader.dataset) > 0:\n",
    "        unlabeled_size = len(unlabeled_loader.dataset)\n",
    "        labeled_size = len(labeled_loader.dataset)\n",
    "        ratio = unlabeled_size / labeled_size\n",
    "    else:\n",
    "        # No unlabeled data scenario: set ratio=1 for a default frequency\n",
    "        ratio = 1.0\n",
    "    \n",
    "    kmeans_update_frequency = max(1, int(ratio))\n",
    "    cluster_centers_torch = None\n",
    "\n",
    "    # To record accuracy and losses per epoch\n",
    "    epoch_stats = {\n",
    "        \"supervised_loss\": [],\n",
    "        \"unsupervised_loss\": [],\n",
    "        \"test_accuracy\": []\n",
    "    }\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "\n",
    "        # Update K-means if unlabeled data is present\n",
    "        if unlabeled_loader is not None and len(unlabeled_loader.dataset) > 0:\n",
    "            if epoch % kmeans_update_frequency == 0 or cluster_centers_torch is None:\n",
    "                cluster_centers_torch = compute_kmeans_centers(model, unlabeled_loader, device, K)\n",
    "                print(f\"Updated K-Means at epoch {epoch+1}\")\n",
    "        else:\n",
    "            # If no unlabeled data, no cluster centers\n",
    "            cluster_centers_torch = None\n",
    "\n",
    "        model.train()\n",
    "        running_supervised_loss = 0.0\n",
    "        running_cluster_loss = 0.0\n",
    "        \n",
    "        if unlabeled_loader is not None:\n",
    "            unlabeled_iter = iter(unlabeled_loader)\n",
    "        else:\n",
    "            unlabeled_iter = None\n",
    "\n",
    "        for x_l, y_l in labeled_loader:\n",
    "            x_l, y_l = x_l.to(device), y_l.to(device)\n",
    "\n",
    "            # Get an unlabeled batch if available\n",
    "            if unlabeled_iter is not None:\n",
    "                try:\n",
    "                    x_u, _ = next(unlabeled_iter)\n",
    "                except StopIteration:\n",
    "                    unlabeled_iter = iter(unlabeled_loader)\n",
    "                    x_u, _ = next(unlabeled_iter)\n",
    "                x_u = x_u.to(device)\n",
    "            else:\n",
    "                x_u = None\n",
    "\n",
    "            # Supervised loss\n",
    "            f_l, logits_l = model(x_l)\n",
    "            supervised_loss = criterion(logits_l, y_l)\n",
    "\n",
    "            # Cluster loss only if we have unlabeled data and cluster centers\n",
    "            if x_u is not None and cluster_centers_torch is not None:\n",
    "                f_u, _ = model(x_u)\n",
    "                with torch.no_grad():\n",
    "                    dists = torch.cdist(f_u, cluster_centers_torch)\n",
    "                    assignments = dists.argmin(dim=1)\n",
    "                assigned_centers = cluster_centers_torch[assignments]\n",
    "                cluster_loss = ((f_u - assigned_centers)**2).mean()\n",
    "            else:\n",
    "                cluster_loss = 0.0\n",
    "\n",
    "            total_loss = supervised_loss + lambda_cluster * cluster_loss\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_supervised_loss += supervised_loss.item()\n",
    "            if x_u is not None:\n",
    "                running_cluster_loss += cluster_loss.item()\n",
    "\n",
    "        avg_supervised_loss = running_supervised_loss / len(labeled_loader)\n",
    "        if unlabeled_loader is not None:\n",
    "            avg_cluster_loss = running_cluster_loss / len(labeled_loader)\n",
    "        else:\n",
    "            avg_cluster_loss = 0.0\n",
    "\n",
    "        # Record losses\n",
    "        epoch_stats[\"supervised_loss\"].append(avg_supervised_loss)\n",
    "        epoch_stats[\"unsupervised_loss\"].append(avg_cluster_loss)\n",
    "\n",
    "        # Evaluate model\n",
    "        test_accuracy = evaluate(model, test_loader, device)\n",
    "        epoch_stats[\"test_accuracy\"].append(test_accuracy)\n",
    "    \n",
    "    # Evaluate at the end\n",
    "    accuracy = evaluate(model, test_loader, device)\n",
    "\n",
    "    # replace prints with TQDM if time\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return model, epoch_stats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# probably dont need model labels\n",
    "def plot_model_losses(epoch_stats_list, model_labels):\n",
    "    \"\"\"\n",
    "    Plots supervised loss and cluster (unsupervised) loss for multiple models.\n",
    "    \n",
    "    Args:\n",
    "        epoch_stats_list (list): List of `epoch_stats` dictionaries from different models.\n",
    "        model_labels (list): List of labels for the corresponding models.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for epoch_stats, label in zip(epoch_stats_list, model_labels):\n",
    "        epochs = range(1, len(epoch_stats[\"supervised_loss\"]) + 1)\n",
    "        # Plot supervised loss\n",
    "        plt.plot(epochs, epoch_stats[\"supervised_loss\"], label=f\"{label} - Supervised Loss\", linestyle='-', marker='o')\n",
    "        # Plot cluster loss\n",
    "        plt.plot(epochs, epoch_stats[\"cluster_loss\"], label=f\"{label} - Cluster Loss\", linestyle='--', marker='x')\n",
    "    \n",
    "    plt.title(\"Supervised and Cluster Losses for Each Model\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated K-Means at epoch 1\n",
      "Updated K-Means at epoch 5\n",
      "Updated K-Means at epoch 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Always 20% labeled\n",
    "# For the benchmark scenario: unlabeled_ratio=0.0 means no unlabeled data used\n",
    "labeled_set, unlabeled_set = create_labeled_unlabeled_subsets(trainset, labeled_ratio=0.2, unlabeled_ratio=0)\n",
    "labeled_loader, unlabeled_loader, test_loader = create_dataloaders(labeled_set, unlabeled_set, testset, batch_size=32)\n",
    "\n",
    "# Train model\n",
    "base_model = CNN()\n",
    "base_model, base_stats = train_model(base_model, labeled_loader, unlabeled_loader, test_loader, device,\n",
    "            num_epochs=10, lr=0.001, K=10, lambda_cluster=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_labeled_unlabeled_subsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m model_labels \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# To store model labels for plotting\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unlabeled_ratio \u001b[38;5;129;01min\u001b[39;00m unlabeled_ratios:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Create labeled and unlabeled subsets\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     labeled_set, unlabeled_set \u001b[38;5;241m=\u001b[39m create_labeled_unlabeled_subsets(trainset, labeled_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, unlabeled_ratio\u001b[38;5;241m=\u001b[39munlabeled_ratio)\n\u001b[1;32m     31\u001b[0m     labeled_loader, unlabeled_loader, test_loader \u001b[38;5;241m=\u001b[39m create_dataloaders(labeled_set, unlabeled_set, testset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Train the model with the current ratio\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_labeled_unlabeled_subsets' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# models = []\n",
    "# epoch_stats = []\n",
    "\n",
    "# unlabeled_ratios = values = [round(x * 0.2, 1) for x in range(1, 6)]  # Multiples of 0.2 from 0.2 to 1.0\n",
    "\n",
    "# for unlabeled_ratio in unlabeled_ratios:\n",
    "#     labeled_set, unlabeled_set = create_labeled_unlabeled_subsets(trainset, labeled_ratio=0.2, unlabeled_ratio=1)\n",
    "#     labeled_loader, unlabeled_loader, test_loader = create_dataloaders(labeled_set, unlabeled_set, testset, batch_size=32)\n",
    "\n",
    "#     # train models with the ratios\n",
    "#     model = CNN()\n",
    "\n",
    "#     tmodel, epoch_stats = train_model(model, labeled_loader, unlabeled_loader, test_loader, device,\n",
    "#                 num_epochs=10, lr=0.001, K=10, lambda_cluster=0.5)\n",
    "\n",
    "#     # save model     \n",
    "#     models.append(model)\n",
    "\n",
    "#     epoch_stats.append(epoch_stats)\n",
    "   \n",
    "# Generate unlabeled ratios\n",
    "unlabeled_ratios = [round(x * 0.2, 1) for x in range(1, 6)]  # Multiples of 0.2 from 0.2 to 1.0\n",
    "\n",
    "models = []\n",
    "all_epoch_stats = []  # To store epoch_stats for all models\n",
    "model_labels = []  # To store model labels for plotting\n",
    "\n",
    "for unlabeled_ratio in unlabeled_ratios:\n",
    "    # Create labeled and unlabeled subsets\n",
    "    labeled_set, unlabeled_set = create_labeled_unlabeled_subsets(trainset, labeled_ratio=0.2, unlabeled_ratio=unlabeled_ratio)\n",
    "    labeled_loader, unlabeled_loader, test_loader = create_dataloaders(labeled_set, unlabeled_set, testset, batch_size=32)\n",
    "\n",
    "    # Train the model with the current ratio\n",
    "    model = CNN()\n",
    "    trained_model, epoch_stats = train_model(model, labeled_loader, unlabeled_loader, test_loader, device,\n",
    "                                             num_epochs=10, lr=0.001, K=10, lambda_cluster=0.5)\n",
    "\n",
    "    # Save model and stats\n",
    "    models.append(trained_model)\n",
    "    all_epoch_stats.append(epoch_stats)\n",
    "    model_labels.append(f\"Unlabeled Ratio {unlabeled_ratio:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot supervised and cluster losses for all models\n",
    "plot_model_losses(all_epoch_stats, model_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RANDOM_STATE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 41\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Example usage after training:\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Assume `model` is trained, `testloader` is ready, and `device` is defined\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# have 'models' right now. \u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# probably want to run tSNE for the benchmark model (trained with only labeled data), and the last trained model (using all unlabeled data)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m features, labels \u001b[38;5;241m=\u001b[39m extract_features(model, testloader, device)\n\u001b[0;32m---> 41\u001b[0m visualize_tsne(features, labels, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-SNE of Test Set Features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[114], line 24\u001b[0m, in \u001b[0;36mvisualize_tsne\u001b[0;34m(features, labels, title)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_tsne\u001b[39m(features, labels, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-SNE Visualization\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# apply tSNE\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE)\n\u001b[1;32m     26\u001b[0m     features_2d \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(features)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Plot results\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RANDOM_STATE' is not defined"
     ]
    }
   ],
   "source": [
    "# # from sklearn.manifold import TSNE\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # # extracting the features from last layer\n",
    "# # def extract_features(model, dataloader, device):\n",
    "# #     model.eval()\n",
    "# #     all_features = []\n",
    "# #     all_labels = []\n",
    "\n",
    "# #     with torch.no_grad():\n",
    "# #         for inputs, labels in dataloader:\n",
    "# #             inputs, labels = inputs.to(device), labels.to(device)\n",
    "# #             features = model.feature_extractor(inputs)  # shape: [batch_size, feature_dim]\n",
    "# #             all_features.append(features.cpu().numpy())\n",
    "# #             all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# #     all_features = np.concatenate(all_features, axis=0)\n",
    "# #     all_labels = np.concatenate(all_labels, axis=0)\n",
    "# #     return all_features, all_labels\n",
    "\n",
    "# # def visualize_tsne(features, labels, title=\"t-SNE Visualization\"):\n",
    "\n",
    "#  #    # apply tSNE\n",
    "# #     tsne = TSNE(n_components=2, random_state=RANDOM_STATE)\n",
    "\n",
    "#     feature# s_2d = tsne.fit_transform(features)\n",
    "\n",
    "#     # Plot # results\n",
    "#     plt.fig# ure(figsize=(10, 8))\n",
    "#     scatter#  = plt.scatter(features_2d[:,0], features_2d[:,1], c=labels, cmap='tab10', alpha=0.7)\n",
    "#     plt.col# orbar(scatter, ticks=range(10))\n",
    "#     plt.tit# le(title)\n",
    "#     plt.sho# w()\n",
    "\n",
    "# # Example u# sage after training:\n",
    "# # Assume `m# odel` is trained, `testloader` is ready, and `device` is defined\n",
    "\n",
    "# # have 'models' right now. \n",
    "# # probably want to run tSNE for the benchmark model (trained with only labeled data), and the last trained model (using all unlabeled data)\n",
    "# features, la# bels = extract_features(mode# l, testloader, device)\n",
    "# visualize_tsne(features, labels, title=\"t-SNE of Test Set Features\")\n",
    "# # # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each epoch:\n",
    "    1. Supervised Phase:\n",
    "        - For each batch in labeled_loader:\n",
    "            a. Pass images through the labeled_labeled_model to get predictions (logits).\n",
    "            b. Compute supervised loss (cross-entropy).\n",
    "            c. Backpropagate and update labeled_labeled_model weights.\n",
    "\n",
    "    2. Unsupervised Phase:\n",
    "        a. Extract features for all images in unlabeled_loader.\n",
    "        b. Perform clustering (e.g., K-Means) on the features.\n",
    "        c. For each batch in unlabeled_loader:\n",
    "            - Compute clustering loss (distance to cluster centers).\n",
    "            - Backpropagate and update the feature extractor.\n",
    "\n",
    "    Log both supervised and unsupervised losses.\n",
    "    Evaluate on the test set to track performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
